{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "09. Run an object detection model on your webcam\n==================================================\n\nThis article will shows how to play with pre-trained object detection models by running\nthem directly on your webcam video stream.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>- This tutorial has only been tested in a MacOS environment\n    - Python packages required: cv2, matplotlib\n    - You need a webcam :)\n    - Python compatible with matplotlib rendering, installed as a framework in MacOS see guide `here <https://matplotlib.org/faq/osx_framework.html>`__</p></div>\n\n\nLoading the model and webcam\n----------------------------\nFinished preparation? Let's get started!\nFirst, import the necessary libraries into python.\n\n.. code-block:: python\n\n    import time\n\n    import gluoncv as gcv\n    from gluoncv.utils import try_import_cv2\n    cv2 = try_import_cv2()\n    import mxnet as mx\n\n\nIn this tutorial we use ``ssd_512_mobilenet1.0_voc``, a snappy network with good accuracy that should be\nwell above 1 frame per second on most laptops. Feel free to try a different model from\nthe `Gluon Model Zoo <../../model_zoo/detection.html>`__ !\n\n.. code-block:: python\n\n    # Load the model\n    net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_voc', pretrained=True)\n    # Compile the model for faster speed\n    net.hybridize()\n\n\nWe create the webcam handler in opencv to be able to acquire the frames:\n\n.. code-block:: python\n\n    # Load the webcam handler\n    cap = cv2.VideoCapture(0)\n    time.sleep(1) ### letting the camera autofocus\n\n\nDetection loop\n--------------\n\nThe detection loop consists of four phases:\n\n* loading the webcam frame\n\n* pre-processing the image\n\n* running the image through the network\n\n* updating the output with the resulting predictions\n\n\n.. code-block:: python\n\n    axes = None\n    NUM_FRAMES = 200 # you can change this\n    for i in range(NUM_FRAMES):\n        # Load frame from the camera\n        ret, frame = cap.read()\n\n        # Image pre-processing\n        frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')\n        rgb_nd, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=700)\n\n        # Run frame through network\n        class_IDs, scores, bounding_boxes = net(rgb_nd)\n\n        # Display the result\n        img = gcv.utils.viz.cv_plot_bbox(frame, bounding_boxes[0], scores[0], class_IDs[0], class_names=net.classes)\n        gcv.utils.viz.cv_plot_image(img)\n        cv2.waitKey(1)\n\n\nWe release the webcam before exiting the script\n\n.. code-block:: python\n\n    cap.release()\n    cv2.destroyAllWindows()\n\nResults\n---------\n\nDownload the script to run the demo:\n\n:download:`Download demo_webcam_run.py<../../../scripts/detection/demo_webcam_run.py>`\n\n\nRun the script using `pythonw` on MacOS:\n\n.. code-block:: bash\n\n    pythonw demo_webcam_run.py --num-frames 200\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>On MacOS, to enable matplotlib rendering you need python installed as a framework,\n    see guide `here <https://matplotlib.org/faq/osx_framework.html>`__</p></div>\n\n\nIf all goes well you should be able to detect objects from the available\nclasses of the VOC dataset. That includes persons, chairs and TV Screens!\n\n![](https://media.giphy.com/media/9JvoKeUeCt4bdRf3Cv/giphy.gif)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}